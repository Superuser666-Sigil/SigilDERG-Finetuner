# Checkpoint File Structure

When a checkpoint is saved during training, the following files are created in each checkpoint directory (e.g., `out/llama8b-rust-qlora-phase1/checkpoint-1000/`):

## Files Generated by HuggingFace Transformers Trainer

1. **`trainer_state.json`**
   - Training state including:
     - `global_step`: Current training step
     - `epoch`: Current epoch
     - `log_history`: Training metrics history
     - `best_metric`: Best evaluation metric (if applicable)
     - `best_model_checkpoint`: Path to best checkpoint
     - Training arguments summary

2. **`training_args.bin`**
   - Serialized `TrainingArguments` object
   - Contains all training hyperparameters and configuration

3. **`optimizer.pt`**
   - Optimizer state (AdamW, etc.)
   - Required for resuming training with the same optimizer state
   - Note: May be incompatible if model structure changes

4. **`scheduler.pt`**
   - Learning rate scheduler state
   - Preserves scheduler state for consistent LR scheduling when resuming

5. **`rng_state.pth`**
   - Random number generator state
   - Ensures reproducibility when resuming training

6. **`README.md`**
   - Auto-generated model card by HuggingFace
   - Contains model metadata, training info, and usage instructions
   - Useful for sharing checkpoints on HuggingFace Hub

7. **`config.json`**
   - Model configuration (architecture, hidden size, layers, etc.)
   - Required for loading the model

8. **`generation_config.json`**
   - Generation parameters (temperature, top_p, etc.)
   - Used when generating text with the model

## Files Generated by PEFT (LoRA Adapters)

9. **`adapter_config.json`**
   - PEFT adapter configuration:
     - LoRA rank (`r`)
     - LoRA alpha (`lora_alpha`)
     - LoRA dropout (`lora_dropout`)
     - Target modules (which layers have adapters)
     - Task type (`CAUSAL_LM`)
     - Base model name

10. **`adapter_model.bin`** or **`adapter_model.safetensors`**
    - LoRA adapter weights (much smaller than full model)
    - Contains only the trainable parameters
    - Format depends on PEFT version (safetensors is preferred for security)

## File Sizes

- **`adapter_model.bin/safetensors`**: ~50-100 MB (depends on LoRA rank)
- **`optimizer.pt`**: ~50-100 MB (depends on optimizer type)
- **`scheduler.pt`**: Small (~KB)
- **`trainer_state.json`**: Small, grows with training history
- **`training_args.bin`**: Small (~KB)
- **`rng_state.pth`**: Small (~KB)
- **`README.md`**: Small (~KB)
- **`config.json`**: Small (~KB)
- **`generation_config.json`**: Small (~KB)

**Total checkpoint size**: ~100-200 MB per checkpoint (mostly adapter weights + optimizer state)

## Checkpoint Management

- Checkpoints are saved every `save_every` steps (configurable in YAML)
- Only the last `save_total_limit` checkpoints are kept (default: 3)
- Older checkpoints are automatically deleted to save disk space
- The latest checkpoint is always preserved

## Resuming from Checkpoint

When resuming training, the following files are used:
- `adapter_config.json` + `adapter_model.bin/safetensors` → Load PEFT adapter
- `trainer_state.json` → Resume from correct step
- `optimizer.pt` + `scheduler.pt` → Restore optimizer/scheduler state (if compatible)
- `rng_state.pth` → Restore random state for reproducibility

## Notes

- The base model is NOT saved in checkpoints (only LoRA adapters)
- To use a checkpoint, you need the base model (`meta-llama/Meta-Llama-3.1-8B-Instruct`)
- The `README.md` is useful for documenting training runs and sharing on HuggingFace Hub
- `generation_config.json` can be customized for different generation strategies

